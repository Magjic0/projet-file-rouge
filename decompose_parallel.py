
"""
decompose_parallel.py
---------------------
Version Â«Â turboÂ Â» : dÃ©composition FFT ultraâ€‘rapide, inspirÃ©e de ton
script concurrent robuste.

â€¢ Exploite tous les cÅ“urs CPU (ProcessPoolExecutor).
â€¢ Chaque worker :
    1. Charge le .npy (Ã©chantillons int16) â†’ float32.
    2. Calcule np.fft.rfft (magnitude).
    3. Sauvegarde <nom>_fft.npy dans fft_npy/.
    4. Retourne un petit dict : nom, chemin FFT.

â€¢ Pas de gros objets picklÃ©s.
â€¢ Checkpoint CSV toutes les 20 pistes.
â€¢ Fallback sÃ©quentiel si le pool plante.
â€¢ Reprise automatique si le CSV existe dÃ©jÃ .

Usage :
    python decompose_parallel.py
"""

import os, sys, signal, multiprocessing as mp
import numpy as np
import pandas as pd
from concurrent.futures import ProcessPoolExecutor, as_completed

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
NPY_DIR = './dataset/Jazz_Audio_concurrent/freq_npy'
FFT_DIR = './dataset/Jazz_Audio_concurrent/fft_npy'
OUT_CSV = './dataset/jazz_audio_fft_paths.csv'

os.makedirs(FFT_DIR, exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Worker â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def fft_worker(npy_file: str):
    """Calcule la magnitude FFT et la sauvegarde. Renvoie (dict, err)."""
    try:
        path = os.path.join(NPY_DIR, npy_file)
        audio = np.load(path).astype(np.float32)
        magnitude = np.abs(np.fft.rfft(audio))
        fft_name = npy_file.replace('.npy', '_fft.npy')
        fft_path = os.path.join(FFT_DIR, fft_name)
        np.save(fft_path, magnitude)
        return {'Name': npy_file.replace('.npy', '.mid'),
                'FFT_Npy_Path': fft_path}, None
    except Exception as exc:
        return None, f"{npy_file} | {exc}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Utils â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def save_csv(df):
    df.to_csv(OUT_CSV, index=False)
    print(f'ğŸ’¾ Checkpoint : {len(df)} FFTs â†’ {OUT_CSV}')

def sequential(files, df):
    for f in files:
        if f.replace('.npy', '.mid') in df['Name'].values:
            continue
        res, err = fft_worker(f)
        if err:
            print('âš ', err)
            continue
        df = pd.concat([df, pd.DataFrame([res])], ignore_index=True)
        if len(df) % 20 == 0:
            save_csv(df)
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def main():
    if os.path.exists(OUT_CSV):
        df = pd.read_csv(OUT_CSV)
        done = set(df['Name'])
    else:
        df = pd.DataFrame(columns=['Name', 'FFT_Npy_Path'])
        done = set()

    todo = [f for f in os.listdir(NPY_DIR) if f.endswith('.npy') and f.replace('.npy', '.mid') not in done]
    if not todo:
        print('âœ… Tous les fichiers sont dÃ©jÃ  dÃ©composÃ©s.')
        return

    try:
        with ProcessPoolExecutor(mp.cpu_count()) as pool:
            fut2file = {pool.submit(fft_worker, f): f for f in todo}
            for idx, fut in enumerate(as_completed(fut2file), 1):
                try:
                    res, err = fut.result()
                except Exception as exc:
                    file_name = fut2file[fut]
                    print(f'âš  Worker crash sur {file_name}: {exc}')
                    continue

                if err:
                    print('âš ', err)
                    continue

                df = pd.concat([df, pd.DataFrame([res])], ignore_index=True)
                if idx % 20 == 0:
                    save_csv(df)
    except Exception as pool_exc:
        print(f'âŒ ProblÃ¨me avec le pool : {pool_exc}. Passage en sÃ©quentiel.')
        remaining = [f for f in todo if f.replace('.npy', '.mid') not in df['Name'].values]
        df = sequential(remaining, df)

    save_csv(df)
    print('âœ“ FFT terminÃ©.')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Signals â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def _sig_handler(sig, frame):
    print('\nInterruption clavier â€“ sauvegarde avant sortieâ€¦')
    if "df" in globals():
        save_csv(df)  # type: ignore
    sys.exit(0)

if __name__ == '__main__':
    mp.freeze_support()
    signal.signal(signal.SIGINT, _sig_handler)
    signal.signal(signal.SIGTERM, _sig_handler)
    main()
